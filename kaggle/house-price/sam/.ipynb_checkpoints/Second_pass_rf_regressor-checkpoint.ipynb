{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second run at the house price kaggle challenge\n",
    "\n",
    "A medium ai approach at the kaggle house price prediction challenge. Following the approach laid out in the first few lessons of the fast.ai machine learning course\n",
    "\n",
    "For the second approach we'll do some basic feature engineering and tuning of the Random Forest's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './input/train.csv'\n",
    "test_path = './input/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train & test data\n",
    "\n",
    "At this stage not adding any special flags when loading the data. Considering the low file size (and I don't know how to do it) the data hasn't been converted to feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(train_path)\n",
    "test_raw_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.shape, test_raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.tail(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The simplest start for this challenge is to add the Total Sq.F. feature, which is just the sum of the available area features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['TotalSF'] = raw_df['GrLivArea'] + raw_df['TotalBsmtSF'] + raw_df['GarageArea'] + raw_df['EnclosedPorch'] + raw_df['ScreenPorch']\n",
    "test_raw_df['TotalSF'] = test_raw_df['GrLivArea'] + test_raw_df['TotalBsmtSF'] + test_raw_df['GarageArea'] + test_raw_df['EnclosedPorch'] + test_raw_df['ScreenPorch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling null values in raw data\n",
    "\n",
    "Since the plan is to use one hot encoding we need to remove null values from the data sets. By reviewiing the data it seems there are three simple options:\n",
    "\n",
    "1. Drop feature\n",
    "For features that have a large number of null values and don't appear to be important we can just remove them from the data set\n",
    "\n",
    "2. Fill missing with mean\n",
    "For continuous features we can simply take the mean value\n",
    "\n",
    "3. Create 'missing' category\n",
    "For categorical features we can create a value for missing data. This makes sense since a missing value make actually hold meaning, e.g. the property does not have a pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "null_features_count = raw_df.isnull().sum()\n",
    "null_features_count = null_features_count[null_features_count > 0]\n",
    "null_features_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set difference \n",
    "\n",
    "We need to repeat the same process for the test set, i.e. make all the same transformations. \n",
    "In particular we need to see where the test set differs from the training set so that we don't miss transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_null_features_count = test_raw_df.isnull().sum()\n",
    "test_null_features_count = test_null_features_count[test_null_features_count > 0]\n",
    "\n",
    "test_train_feature_diff = test_null_features_count.index.difference(null_features_count.index)\n",
    "test_train_feature_diff.append(null_features_count.index.difference(test_null_features_count.index))\n",
    "\n",
    "test_null_features_count[test_train_feature_diff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created lists of feature names for missing values\n",
    "large_null_features = [\n",
    "    'MiscFeature'\n",
    "]\n",
    "fill_mean_features = [\n",
    "    'MasVnrArea', \n",
    "    'GarageYrBlt', \n",
    "    'LotFrontage',\n",
    "    'BsmtFinSF1',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath',\n",
    "    'BsmtUnfSF',\n",
    "    'GarageArea',\n",
    "    'GarageCars',\n",
    "    'TotalBsmtSF'\n",
    "]\n",
    "# this is only the test set at the minute, review the training set to see what can be switched\n",
    "fill_most_common_cat_features = [\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'Functional',\n",
    "    'KitchenQual',\n",
    "    'MSZoning',\n",
    "    'SaleType',\n",
    "    'Utilities' \n",
    "]\n",
    "create_NA_cat_features = [\n",
    "    'Alley',\n",
    "    'PoolQC',\n",
    "    'BsmtCond', \n",
    "    'BsmtFinType1', \n",
    "    'BsmtFinType2',\n",
    "    'BsmtQual', \n",
    "    'BsmtExposure',\n",
    "    'Fence',\n",
    "    'FireplaceQu', \n",
    "    'GarageCond', \n",
    "    'GarageFinish', \n",
    "    'GarageQual',\n",
    "    'GarageType'\n",
    "]\n",
    "create_none_cat_features = [\n",
    "    'MasVnrType'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    for col in create_NA_cat_features:\n",
    "        df[col].fillna(value='NA', inplace=True)\n",
    "\n",
    "    for col in create_none_cat_features:\n",
    "        df[col].fillna(value='None', inplace=True)\n",
    "\n",
    "    for col in fill_mean_features:\n",
    "        df[col].fillna(value=df[col].mean(), inplace=True)\n",
    "\n",
    "    df.Electrical.fillna(value='Mix', inplace=True)\n",
    "\n",
    "    df.drop(large_null_features, axis=1, inplace=True)\n",
    "    \n",
    "    for col in fill_most_common_cat_features:\n",
    "        df[col].fillna(value=df[col].value_counts().idxmax(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_missing_values(raw_df)\n",
    "handle_missing_values(test_raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create first model\n",
    "\n",
    "Firstly we need to take the log of the Sale Price so that higher sale prices don't affect the model.\n",
    "\n",
    "Then we will create a random forest with just the default values to see what score we can achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.SalePrice = np.log(raw_df.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_df = pd.get_dummies(data=raw_df)\n",
    "test_one_hot_encoded_df = pd.get_dummies(data=test_raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories in train set that don't appear in test set\n",
    "\n",
    "This is interesting, there are more features in the train set than the test set. This is caused by the one hot encoding. The training set must have categories that don't appear in the test set. I think the best way to handle this would be to use train_cats on the features, but I'll try that another time, and just drop the differences for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_df.shape, test_one_hot_encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_features = one_hot_encoded_df.columns.difference(test_one_hot_encoded_df.columns)\n",
    "test_missing_features = test_missing_features.delete(test_missing_features.get_loc('SalePrice'))\n",
    "one_hot_encoded_df.drop(test_missing_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_df.drop('SalePrice', axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_encoded_df, raw_df.SalePrice, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1)\n",
    "rf.fit(X=X_train, y=y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = pd.DataFrame({'cols': one_hot_encoded_df.columns, 'imp': rf.feature_importances_}).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance[:20].plot('cols', 'imp', 'barh', figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test set predictions for Kaggle\n",
    "\n",
    "Create predictions from model for Kaggle submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_df(model, test_data_df, test_data_ids):\n",
    "    kaggle_preds = np.exp(model.predict(test_data_df))\n",
    "    return pd.DataFrame({'Id': test_data_ids, 'SalePrice': kaggle_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_to_csv(submission, filename):\n",
    "    submission.to_csv(filename,index=False)\n",
    "    print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = create_submission_df(rf, test_one_hot_encoded_df, test_raw_df.Id)\n",
    "# save_submission_to_csv(submission, 'Housing Predictions 1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
